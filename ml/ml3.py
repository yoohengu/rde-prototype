"""
ê¸°ì—… ë¶€ë„ ì˜ˆì¸¡ ëª¨ë¸ ë¹„êµ: ì›ë³¸ ë°ì´í„° vs SMOTE ì¦ê°• ë°ì´í„°
- ë™ì¼í•œ ì•Œê³ ë¦¬ì¦˜ 3ê°€ì§€ ì‚¬ìš© (Logistic Regression, Random Forest, Gradient Boosting)
- ëª¨ë¸ A: ì›ë³¸ ë°ì´í„° + class_weight ì¡°ì •
- ëª¨ë¸ B: SMOTE ì¦ê°• ë°ì´í„°
"""
from dotenv import load_dotenv
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score, 
    roc_curve, precision_recall_curve, f1_score, accuracy_score,
    precision_score, recall_score
)
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

print("=" * 100)
print("ê¸°ì—… ë¶€ë„ ì˜ˆì¸¡ ëª¨ë¸ ë¹„êµ: ì›ë³¸ ë°ì´í„° vs SMOTE ì¦ê°• ë°ì´í„°")
print("=" * 100)

# ==================== 1. ë°ì´í„° ë¡œë“œ ====================
print("\n[1] ë°ì´í„° ë¡œë“œ ì¤‘...")
load_dotenv()
df_path = os.getenv("DATA_ML")
df = pd.read_csv(df_path)
print(f"âœ“ ë°ì´í„° shape: {df.shape}")

# ==================== 2. íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸ ====================
target_col = 'ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)'
print(f"\n[2] íƒ€ê²Ÿ ë³€ìˆ˜: {target_col}")
print(f"\ní´ë˜ìŠ¤ ë¶„í¬:")
print(df[target_col].value_counts())
print(f"\në¶€ë„ ë¹„ìœ¨: {df[target_col].mean():.2%}")

# ==================== 3. íŠ¹ì„± ì„ íƒ ë° ì „ì²˜ë¦¬ ====================
print("\n[3] íŠ¹ì„± ì„ íƒ ë° ì „ì²˜ë¦¬...")

exclude_cols = [
    'ê¸°ì¤€ë…„ì›”', 'ì—…ì¢…(ì¤‘ë¶„ë¥˜)', 'ì„¤ë¦½ì¼ì', 'ì£¼ì†Œì§€ì‹œêµ°êµ¬',
    target_col, 'ê¸°ì—…ì‹ ìš©í‰ê°€ë“±ê¸‰(êµ¬ê°„í™”)'
]

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
feature_cols = [col for col in numeric_cols if col not in exclude_cols]

print(f"ì´ˆê¸° íŠ¹ì„± ìˆ˜: {len(feature_cols)}")

X = df[feature_cols].copy()
y = df[target_col].copy()

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
missing_ratio = (X.isnull().sum() / len(X) * 100)
high_missing_cols = missing_ratio[missing_ratio > 50].index.tolist()
X = X.drop(columns=high_missing_cols)
print(f"ê²°ì¸¡ì¹˜ 50% ì´ìƒ ì»¬ëŸ¼ {len(high_missing_cols)}ê°œ ì œê±°")

X = X.fillna(X.median())
X = X.replace([np.inf, -np.inf], np.nan)
X = X.fillna(X.median())

print(f"ìµœì¢… íŠ¹ì„± ìˆ˜: {X.shape[1]}")

# ==================== 4. ë°ì´í„° ë¶„í•  ====================
print("\n[4] ë°ì´í„° ë¶„í•  (Train 70% / Test 30%)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
print(f"\ní•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
print(f"  - ì •ìƒ ê¸°ì—…: {(y_train==0).sum()}")
print(f"  - ë¶€ë„ ê¸°ì—…: {(y_train==1).sum()}")
print(f"  - ë¶€ë„ìœ¨: {y_train.mean():.2%}")

# ==================== 5. SMOTE ì ìš© ====================
print("\n[5] SMOTE ë°ì´í„° ì¦ê°•...")

# SMOTE ì ìš© ì „ k_neighbors ì„¤ì •
n_minority = (y_train==1).sum()
k_neighbors = min(5, n_minority - 1) if n_minority > 1 else 1

smote = SMOTE(random_state=42, k_neighbors=k_neighbors, sampling_strategy=0.5)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print(f"\nSMOTE ì ìš© í›„ í•™ìŠµ ë°ì´í„°:")
print(f"  - ì •ìƒ ê¸°ì—…: {(y_train_smote==0).sum()}")
print(f"  - ë¶€ë„ ê¸°ì—…: {(y_train_smote==1).sum()}")
print(f"  - ë¶€ë„ìœ¨: {y_train_smote.mean():.2%}")
print(f"  - ì´ ìƒ˜í”Œ: {len(y_train_smote)} (ì¦ê°€: {len(y_train_smote) - len(y_train)})")

# ==================== 6. íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ====================
print("\n[6] íŠ¹ì„± ìŠ¤ì¼€ì¼ë§...")

# ì›ë³¸ ë°ì´í„°ìš© ìŠ¤ì¼€ì¼ëŸ¬
scaler_original = StandardScaler()
X_train_scaled = scaler_original.fit_transform(X_train)
X_test_scaled = scaler_original.transform(X_test)

# SMOTE ë°ì´í„°ìš© ìŠ¤ì¼€ì¼ëŸ¬
scaler_smote = StandardScaler()
X_train_smote_scaled = scaler_smote.fit_transform(X_train_smote)
X_test_smote_scaled = scaler_smote.transform(X_test)

print("âœ“ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ")

# ==================== 7. ëª¨ë¸ ì •ì˜ ====================
print("\n[7] ëª¨ë¸ ì •ì˜...")

# ëª¨ë¸ A: ì›ë³¸ ë°ì´í„° + class_weight ì¡°ì •
models_original = {
    'Logistic Regression': LogisticRegression(
        max_iter=1000,
        random_state=42,
        class_weight='balanced',
        solver='lbfgs'
    ),
    'Random Forest': RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42,
        class_weight='balanced',
        n_jobs=-1
    ),
    'Gradient Boosting': GradientBoostingClassifier(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )
}

# ëª¨ë¸ B: SMOTE ì¦ê°• ë°ì´í„°
models_smote = {
    'Logistic Regression': LogisticRegression(
        max_iter=1000,
        random_state=42,
        solver='lbfgs'
    ),
    'Random Forest': RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42,
        n_jobs=-1
    ),
    'Gradient Boosting': GradientBoostingClassifier(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )
}

print("âœ“ 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ì¤€ë¹„ ì™„ë£Œ")

# ==================== 8. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ====================
print("\n[8] ëª¨ë¸ í•™ìŠµ ë° í‰ê°€...")
print("=" * 100)

results_original = {}
results_smote = {}

# 8-1. ì›ë³¸ ë°ì´í„° ëª¨ë¸ í•™ìŠµ
print("\n[ëª¨ë¸ A] ì›ë³¸ ë°ì´í„° + class_weight ì¡°ì •")
print("-" * 100)

for name, model in models_original.items():
    print(f"\n{name} í•™ìŠµ ì¤‘...")
    model.fit(X_train_scaled, y_train)
    
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    
    # í‰ê°€ ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    
    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_test, y_pred)
    
    results_original[name] = {
        'model': model,
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'roc_auc': roc_auc,
        'confusion_matrix': cm
    }
    
    print(f"  Accuracy:  {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall:    {recall:.4f}")
    print(f"  F1 Score:  {f1:.4f}")
    print(f"  ROC AUC:   {roc_auc:.4f}")

# 8-2. SMOTE ë°ì´í„° ëª¨ë¸ í•™ìŠµ
print("\n" + "=" * 100)
print("\n[ëª¨ë¸ B] SMOTE ì¦ê°• ë°ì´í„°")
print("-" * 100)

for name, model in models_smote.items():
    print(f"\n{name} í•™ìŠµ ì¤‘...")
    model.fit(X_train_smote_scaled, y_train_smote)
    
    y_pred = model.predict(X_test_smote_scaled)
    y_pred_proba = model.predict_proba(X_test_smote_scaled)[:, 1]
    
    # í‰ê°€ ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    
    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_test, y_pred)
    
    results_smote[name] = {
        'model': model,
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'roc_auc': roc_auc,
        'confusion_matrix': cm
    }
    
    print(f"  Accuracy:  {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall:    {recall:.4f}")
    print(f"  F1 Score:  {f1:.4f}")
    print(f"  ROC AUC:   {roc_auc:.4f}")

# ==================== 9. ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ====================
print("\n" + "=" * 100)
print("[9] ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”")
print("=" * 100)

comparison_data = []

for name in models_original.keys():
    # ì›ë³¸ ë°ì´í„° ê²°ê³¼
    comparison_data.append({
        'ëª¨ë¸': name,
        'ë°ì´í„°': 'ì›ë³¸',
        'Accuracy': results_original[name]['accuracy'],
        'Precision': results_original[name]['precision'],
        'Recall': results_original[name]['recall'],
        'F1 Score': results_original[name]['f1'],
        'ROC AUC': results_original[name]['roc_auc']
    })
    
    # SMOTE ë°ì´í„° ê²°ê³¼
    comparison_data.append({
        'ëª¨ë¸': name,
        'ë°ì´í„°': 'SMOTE',
        'Accuracy': results_smote[name]['accuracy'],
        'Precision': results_smote[name]['precision'],
        'Recall': results_smote[name]['recall'],
        'F1 Score': results_smote[name]['f1'],
        'ROC AUC': results_smote[name]['roc_auc']
    })

comparison_df = pd.DataFrame(comparison_data)

print("\nì „ì²´ ì„±ëŠ¥ ë¹„êµ:")
print("=" * 120)
print(f"{'ëª¨ë¸':<25} {'ë°ì´í„°':<10} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1 Score':<12} {'ROC AUC':<12}")
print("=" * 120)

for _, row in comparison_df.iterrows():
    print(f"{row['ëª¨ë¸']:<25} {row['ë°ì´í„°']:<10} {row['Accuracy']:<12.4f} "
          f"{row['Precision']:<12.4f} {row['Recall']:<12.4f} "
          f"{row['F1 Score']:<12.4f} {row['ROC AUC']:<12.4f}")

# ==================== 10. ëª¨ë¸ë³„ ì„±ëŠ¥ í–¥ìƒ/í•˜ë½ ë¶„ì„ ====================
print("\n" + "=" * 100)
print("[10] SMOTE ì ìš© íš¨ê³¼ ë¶„ì„ (ì›ë³¸ ëŒ€ë¹„ ë³€í™”)")
print("=" * 100)

print(f"\n{'ëª¨ë¸':<25} {'Accuracy':<15} {'Precision':<15} {'Recall':<15} {'F1 Score':<15} {'ROC AUC':<15}")
print("=" * 100)

for name in models_original.keys():
    acc_diff = results_smote[name]['accuracy'] - results_original[name]['accuracy']
    prec_diff = results_smote[name]['precision'] - results_original[name]['precision']
    rec_diff = results_smote[name]['recall'] - results_original[name]['recall']
    f1_diff = results_smote[name]['f1'] - results_original[name]['f1']
    roc_diff = results_smote[name]['roc_auc'] - results_original[name]['roc_auc']
    
    acc_sign = "ğŸ“ˆ" if acc_diff > 0 else "ğŸ“‰" if acc_diff < 0 else "â¡ï¸"
    prec_sign = "ğŸ“ˆ" if prec_diff > 0 else "ğŸ“‰" if prec_diff < 0 else "â¡ï¸"
    rec_sign = "ğŸ“ˆ" if rec_diff > 0 else "ğŸ“‰" if rec_diff < 0 else "â¡ï¸"
    f1_sign = "ğŸ“ˆ" if f1_diff > 0 else "ğŸ“‰" if f1_diff < 0 else "â¡ï¸"
    roc_sign = "ğŸ“ˆ" if roc_diff > 0 else "ğŸ“‰" if roc_diff < 0 else "â¡ï¸"
    
    print(f"{name:<25} {acc_sign}{acc_diff:+.4f}      {prec_sign}{prec_diff:+.4f}      "
          f"{rec_sign}{rec_diff:+.4f}      {f1_sign}{f1_diff:+.4f}      {roc_sign}{roc_diff:+.4f}")

# ==================== 11. ìƒì„¸ í˜¼ë™ í–‰ë ¬ ë¹„êµ ====================
print("\n" + "=" * 100)
print("[11] í˜¼ë™ í–‰ë ¬ ë¹„êµ")
print("=" * 100)

for name in models_original.keys():
    print(f"\n[{name}]")
    print("-" * 60)
    
    cm_orig = results_original[name]['confusion_matrix']
    cm_smote = results_smote[name]['confusion_matrix']
    
    print(f"\nì›ë³¸ ë°ì´í„°:")
    print(f"  TN: {cm_orig[0,0]:>6}  |  FP: {cm_orig[0,1]:>6}")
    print(f"  FN: {cm_orig[1,0]:>6}  |  TP: {cm_orig[1,1]:>6}")
    
    total_bankrupt = y_test.sum()
    detected_orig = cm_orig[1,1]
    missed_orig = cm_orig[1,0]
    
    print(f"  â†’ ë¶€ë„ íƒì§€ìœ¨: {detected_orig}/{total_bankrupt} ({detected_orig/total_bankrupt*100:.1f}%)")
    print(f"  â†’ ë¶€ë„ ë†“ì¹¨:   {missed_orig}/{total_bankrupt} ({missed_orig/total_bankrupt*100:.1f}%)")
    
    print(f"\nSMOTE ë°ì´í„°:")
    print(f"  TN: {cm_smote[0,0]:>6}  |  FP: {cm_smote[0,1]:>6}")
    print(f"  FN: {cm_smote[1,0]:>6}  |  TP: {cm_smote[1,1]:>6}")
    
    detected_smote = cm_smote[1,1]
    missed_smote = cm_smote[1,0]
    
    print(f"  â†’ ë¶€ë„ íƒì§€ìœ¨: {detected_smote}/{total_bankrupt} ({detected_smote/total_bankrupt*100:.1f}%)")
    print(f"  â†’ ë¶€ë„ ë†“ì¹¨:   {missed_smote}/{total_bankrupt} ({missed_smote/total_bankrupt*100:.1f}%)")
    
    # ê°œì„  íš¨ê³¼
    improvement = detected_smote - detected_orig
    if improvement > 0:
        print(f"\n  âœ… SMOTE ì ìš©ìœ¼ë¡œ {improvement}ê°œ ë¶€ë„ ê¸°ì—… ì¶”ê°€ íƒì§€ ({improvement/total_bankrupt*100:.1f}%p í–¥ìƒ)")
    elif improvement < 0:
        print(f"\n  âš ï¸ SMOTE ì ìš©ìœ¼ë¡œ {abs(improvement)}ê°œ ë¶€ë„ ê¸°ì—… íƒì§€ ê°ì†Œ")
    else:
        print(f"\n  â¡ï¸ íƒì§€ìœ¨ ë³€í™” ì—†ìŒ")

# ==================== 12. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ ì • ====================
print("\n" + "=" * 100)
print("[12] ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ ì •")
print("=" * 100)

# ROC AUC ê¸°ì¤€
best_original_name = max(results_original.items(), key=lambda x: x[1]['roc_auc'])[0]
best_original_auc = results_original[best_original_name]['roc_auc']

best_smote_name = max(results_smote.items(), key=lambda x: x[1]['roc_auc'])[0]
best_smote_auc = results_smote[best_smote_name]['roc_auc']

print(f"\nì›ë³¸ ë°ì´í„° ìµœê³  ëª¨ë¸:")
print(f"  {best_original_name} - ROC AUC: {best_original_auc:.4f}")
print(f"  Recall: {results_original[best_original_name]['recall']:.4f}")
print(f"  F1 Score: {results_original[best_original_name]['f1']:.4f}")

print(f"\nSMOTE ë°ì´í„° ìµœê³  ëª¨ë¸:")
print(f"  {best_smote_name} - ROC AUC: {best_smote_auc:.4f}")
print(f"  Recall: {results_smote[best_smote_name]['recall']:.4f}")
print(f"  F1 Score: {results_smote[best_smote_name]['f1']:.4f}")

# ì „ì²´ ìµœê³  ëª¨ë¸
if best_original_auc > best_smote_auc:
    print(f"\nğŸ† ì „ì²´ ìµœê³  ëª¨ë¸: ì›ë³¸ ë°ì´í„° + {best_original_name}")
    print(f"   ROC AUC: {best_original_auc:.4f}")
else:
    print(f"\nğŸ† ì „ì²´ ìµœê³  ëª¨ë¸: SMOTE ë°ì´í„° + {best_smote_name}")
    print(f"   ROC AUC: {best_smote_auc:.4f}")

# ==================== 13. ê²°ê³¼ ì €ì¥ ====================
print("\n" + "=" * 100)
print("[13] ê²°ê³¼ ì €ì¥")
print("=" * 100)

# ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ì €ì¥
comparison_df.to_csv('model_comparison_original_vs_smote.csv', 
                     index=False, encoding='utf-8-sig')
print("âœ“ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥: model_comparison_original_vs_smote.csv")

# ëª¨ë¸ë³„ ìƒì„¸ ê²°ê³¼ ì €ì¥
detailed_results = []

for name in models_original.keys():
    cm_orig = results_original[name]['confusion_matrix']
    cm_smote = results_smote[name]['confusion_matrix']
    
    detailed_results.append({
        'ëª¨ë¸': name,
        'ë°ì´í„°': 'ì›ë³¸',
        'TN': cm_orig[0,0],
        'FP': cm_orig[0,1],
        'FN': cm_orig[1,0],
        'TP': cm_orig[1,1],
        'ë¶€ë„íƒì§€ìœ¨': f"{cm_orig[1,1]/y_test.sum()*100:.1f}%",
        'Accuracy': results_original[name]['accuracy'],
        'Precision': results_original[name]['precision'],
        'Recall': results_original[name]['recall'],
        'F1 Score': results_original[name]['f1'],
        'ROC AUC': results_original[name]['roc_auc']
    })
    
    detailed_results.append({
        'ëª¨ë¸': name,
        'ë°ì´í„°': 'SMOTE',
        'TN': cm_smote[0,0],
        'FP': cm_smote[0,1],
        'FN': cm_smote[1,0],
        'TP': cm_smote[1,1],
        'ë¶€ë„íƒì§€ìœ¨': f"{cm_smote[1,1]/y_test.sum()*100:.1f}%",
        'Accuracy': results_smote[name]['accuracy'],
        'Precision': results_smote[name]['precision'],
        'Recall': results_smote[name]['recall'],
        'F1 Score': results_smote[name]['f1'],
        'ROC AUC': results_smote[name]['roc_auc']
    })

detailed_df = pd.DataFrame(detailed_results)
detailed_df.to_csv('detailed_comparison_results.csv', 
                   index=False, encoding='utf-8-sig')
print("âœ“ ìƒì„¸ ë¹„êµ ê²°ê³¼ ì €ì¥: detailed_comparison_results.csv")

# ==================== 14. ìµœì¢… ìš”ì•½ ====================
print("\n" + "=" * 100)
print("ë¶„ì„ ì™„ë£Œ!")
print("=" * 100)

print(f"\nâœ“ ì „ì²´ ë°ì´í„°: {len(df):,}ê±´")
print(f"âœ“ ì‚¬ìš© íŠ¹ì„±: {X.shape[1]}ê°œ")
print(f"âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(y_test):,}ê±´ (ë¶€ë„: {y_test.sum()}ê±´)")
print(f"\nâœ“ ë¹„êµ ëª¨ë¸: 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ Ã— 2ê°€ì§€ ë°ì´í„° = ì´ 6ê°œ ëª¨ë¸")
print(f"  - Logistic Regression")
print(f"  - Random Forest")
print(f"  - Gradient Boosting")
print(f"\nâœ“ ì›ë³¸ ë°ì´í„° í•™ìŠµ ìƒ˜í”Œ: {len(y_train):,}ê±´")
print(f"âœ“ SMOTE ë°ì´í„° í•™ìŠµ ìƒ˜í”Œ: {len(y_train_smote):,}ê±´ (ì¦ê°€: {len(y_train_smote)-len(y_train):,}ê±´)")

print(f"\nìƒì„±ëœ íŒŒì¼:")
print(f"  - model_comparison_original_vs_smote.csv")
print(f"  - detailed_comparison_results.csv")

print("\n" + "=" * 100)